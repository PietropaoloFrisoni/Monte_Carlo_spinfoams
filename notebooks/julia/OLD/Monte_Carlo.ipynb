{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea86d4e-8bff-4bce-884d-14b757e35063",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Monte Carlo in spinfoams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21eeb7-99ae-415f-8b03-9f8dadbfe667",
   "metadata": {},
   "source": [
    "Let's consider a spinfoam amplitude $W$ which can be computed as:\n",
    "\n",
    "$$\n",
    "W = \\sum\\limits_{j_1 \\dots j_N} w(j_1 \\dots j_N) \\ ,\n",
    "$$\n",
    "\n",
    "where $j_1 \\dots j_N \\in \\frac{\\mathbb{N}}{2}$ are the discrete spins which must be summed over (this is much more general than the specific case of divergences). Since we want to keep the notation as simple and clean as possible, let's rewrite the above expression as:\n",
    "\n",
    "$$\n",
    "W \\equiv \\sum\\limits_{j \\in \\chi} w(j) \\ ,\n",
    "$$\n",
    "\n",
    "where $j$ in an $N$-dimensional vector of spins and $\\chi$ is the $N$-dimensional set of values that j can assume (spins are constrained by triangular inequalities). This problem is completely deterministic: summing of a function $w(j)$ over the countably many values of $j$ in a set $\\chi$. \n",
    "\n",
    "If we define a random variable $r$ which takes values in $\\chi$ all with equal probability $p$ (so that $\\sum\\limits_{\\iota \\in \\chi} p = 1$) then the sum may be cast as an expectation:\n",
    "\n",
    "$$\n",
    "W = \\sum\\limits_{j \\in \\chi} w(j) = \\frac{1}{p} \\sum\\limits_{j \\in \\chi} w(j) p \\equiv \\frac{1}{p} \\mathbb{E} \\left( w(r) \\right) \\ .\n",
    "$$\n",
    "\n",
    "Namely, $\\mathbb{E} \\left( w(r) \\right)$ is the $\\textbf{expected value}$ of a function $w$ of a discrete random variable $r$ having probability mass function or probability density function $f_{\\chi}=p$ for all the elements $\\iota \\in \\chi$. In particular, notice that if $V$ is the \"volume\" of $\\chi$, namely the sum of all possible elements in $\\chi$ (namely $V = \\sum\\limits_{\\iota \\in \\chi} 1$, which is the total number of configurations that $r$ can assume), then we have $p=\\frac{1}{V}$.\n",
    "\n",
    "The immediate consequence is that our original sum can be approximated by the Monte Carlo method. If we sample $N_{mc}$ values of $r$â€™s, $(r_1,..., r_{N_{mc}})$, and we compute the mean of $w(r)$ over the sample, then we obtain the $\\textbf{Monte Carlo estimate}$ of $W$:\n",
    "\n",
    "$$\n",
    "\\tilde{W}_{N_{mc}} = \\frac{V}{N_{mc}} \\sum\\limits_{i = 1}^{N_{mc}} w(r_i) \\ .\n",
    "$$\n",
    "\n",
    "The law of large numbers ensures that:\n",
    "\n",
    "$$\n",
    "\\lim_{N_{mc} \\to \\infty} \\tilde{W}_{N_{mc}} = W \\ .\n",
    "$$\n",
    "\n",
    "This allows us to write:\n",
    "\n",
    "$$\n",
    "\\tilde{W}_{N_{mc}} \\approx W \\hspace{4mm} \\textrm{for} \\hspace{2mm} N_{mc} \\gg 1 \\ .\n",
    "$$\n",
    "\n",
    "## Measuring the error\n",
    "\n",
    "We defined a Monte Carlo estimate $\\tilde{W}_{N_{mc}}$ of the amplitude $W$. Let's discuss how to evaluate the error due to the finiteness of $N_{mc}$.\n",
    "\n",
    "### Comparing with the exact value\n",
    "\n",
    "The best way to estimate the error (due to the fact that $N_{mc}$ is always finite in a concrete simulation) is by comparing the Monte Carlo estimate with the exact amplitude. This is what we can do only in specific cases (as the self-energy amplitude), but in general the exact amplitude is not feasibly computed: that is precisely why Monte Carlo is required in the first place.\n",
    "\n",
    "### Monte Carlo variance\n",
    "\n",
    "One possibility is to obtain the variance associated with the Monte Carlo estimate as follows. We can associate error bars to $\\tilde{W}_{N_{mc}}$ using the unbiased estimate of the variance. The variance of the Monte Carlo estimate is given by:\n",
    "\n",
    "$$\n",
    "\\textrm{Var} \\left( \\tilde{W}_{N_{mc}} \\right) = \\frac{V^2}{N_{mc} (N_{mc}-1)} \\sum\\limits_{i = 1}^{N_{mc}} \\left( w(r_i) - \\frac{\\tilde{W}_{N_{mc}}}{V} \\right)^2 \\ .\n",
    "$$\n",
    "\n",
    "The estimation of the error of $\\tilde{W}_{N_{mc}}$ is just the square root of the variance:\n",
    "\n",
    "$$\n",
    "\\delta \\tilde{W}_{N_{mc}} \\approx \\sqrt{\\textrm{Var} \\left( \\tilde{W}_{N_{mc}} \\right)} \\ ,\n",
    "$$\n",
    "\n",
    "which decreases as $\\frac{1}{\\sqrt{N_{mc}}}$. Crucially, this result does not depend on the number of dimensions, which is the reason for which this application paves the way to a new range of extremely exciting computations.\n",
    "\n",
    "- Application to divergences $\\textbf{(OBSOLETE: SEE NEW METHOD BELOW)}$\n",
    "\n",
    "In the case of divergences, we proceed as follows. Following the notation introduced above, let me write the amplitude computed with all bulk spins in range $[0, K]$ as:\n",
    "\n",
    "$$\n",
    "W_{K} = \\sum\\limits_{j \\in \\chi}^{K} w(j) \\ .\n",
    "$$\n",
    "\n",
    "This can be expressed as the sum of $\\textit{partial amplitudes}$:\n",
    "\n",
    "\\begin{align}\n",
    "W_{K} & = W_{0} + (W_{\\frac{1}{2}} - W_{0}) + (W_{1} - W_{\\frac{1}{2}}) + \\dots + (W_{K} - W_{K-\\frac{1}{2}}) \\\\\n",
    " & \\equiv W'_{0} + W'_{\\frac{1}{2}} + W'_{1} + \\dots + W'_{K} \\ ,\n",
    "\\end{align}\n",
    "\n",
    "where we defined $W'_{0} \\equiv W_{0}$ and $W'_{i} \\equiv \\left( W_{i} - W_{i - \\frac{1}{2}} \\right)$ for $i \\geq \\frac{1}{2}$. Therefore, we can compute the Monte Carlo estimate of $W'_{i}$ using $N_{mc}$ iterations:\n",
    "\n",
    "$$\n",
    "W'_{i} \\approx  \\left( \\tilde{W}'_{i N_{mc}} \\pm \\delta \\tilde{W}'_{i N_{mc}} \\right)\n",
    "$$\n",
    "\n",
    "for all $i$'s and then sum, propagating the error according to the standard procedure. It could make sense to use a different number of iterations $N_{mc}$ which increases along with $i$, but for now let's keep things as simple as possible.\n",
    "\n",
    "We end up with a Monte Carlo estimate of the original amplitude:\n",
    "\n",
    "$$\n",
    "W_{K} \\approx  \\left( \\tilde{W}_{K N_{mc}} \\pm \\delta \\tilde{W}_{K N_{mc}} \\right) \\ ,\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\tilde{W}_{K N_{mc}} = \\tilde{W}'_{0 N_{mc}} + \\tilde{W}'_{\\frac{1}{2} N_{mc}} + \\dots + \\tilde{W}'_{K N_{mc}}$ \n",
    "\n",
    "- $\\delta \\tilde{W}_{K N_{mc}} = \\delta \\tilde{W}'_{0 N_{mc}} + \\delta \\tilde{W}'_{\\frac{1}{2} N_{mc}} + \\dots + \\delta \\tilde{W}'_{K N_{mc}}$ \n",
    "\n",
    "### Comparing multiple trials\n",
    "\n",
    "This is the method that until now has proved to be the most effective, versatile, unbiased and easy to generalize. The idea is simply that the soundness of the Monte Carlo fluctuations can be estimated by comparing many different trials (or runs).\n",
    "\n",
    "Namely, we compute $T$ times the Monte carlo estimate $\\tilde{W}_{N_{mc}}$, obtaining $T$ different estimates: $\\tilde{W}^{1}_{N_{mc}}, \\tilde{W}^{2}_{N_{mc}} \\dots \\tilde{W}^{T}_{N_{mc}}$. It is now straightforward to consider as (best) monte carlo estimate the average of the single estimate over $T$ trials:\n",
    "\n",
    "$$\n",
    "\\tilde{W}^{avg}_{N_{mc}} = \\frac{1}{T} \\sum\\limits_{i = 1}^{T} \\tilde{W}^{i}_{N_{mc}} \\ ,\n",
    "$$\n",
    "\n",
    "associating as error the standard deviation (possibly multiplied by a constant) of the trials:\n",
    "\n",
    "$$\n",
    "\\delta \\tilde{W}^{avg}_{N_{mc}} \\approx \\sqrt{\\frac{1}{T} \\sum\\limits_{i = 1}^{T} \\left( \\tilde{W}^{i}_{N_{mc}} - \\tilde{W}^{avg}_{N_{mc}} \\right)^2 } \\ .\n",
    "$$\n",
    "\n",
    "This is the method that, so far, produces (by far) the smallest error associated with amplitude. This is in excellent agreement with the comparison with the exact amplitude data (i.e. the first method on this list).\n",
    "\n",
    "Also, in the extrapolation for $\\Delta l \\rightarrow \\infty$ this method is the only resource we have, since we don't know how to propagate the error.\n",
    "\n",
    "For these reason(s), this method is the one currently used in plots and related notebook.\n",
    "\n",
    "In the case of divergences, this methods is completely straightforward. In fact, we don't even need to define the partial amplitudes. For each finite $K$ we simply compute the Monte Carlo estimate using $N_{MC}$ iterations and $T$ trials:  \n",
    "\n",
    "$$\n",
    "\\tilde{W}^{avg}_{K N_{mc}} = \\frac{1}{T} \\sum\\limits_{i = 1}^{T} \\tilde{W}^{i}_{K N_{mc}} \\ ,\n",
    "$$\n",
    "\n",
    "and the standard deviation associated with it:\n",
    "\n",
    "$$\n",
    "\\delta \\tilde{W}^{avg}_{K N_{mc}} \\approx \\sqrt{\\frac{1}{T} \\sum\\limits_{i = 1}^{T} \\left( \\tilde{W}^{i}_{K N_{mc}} - \\tilde{W}^{avg}_{K N_{mc}} \\right)^2 } \\ .\n",
    "$$\n",
    "\n",
    "We end up with a Monte Carlo estimate of the original amplitude:\n",
    "\n",
    "$$\n",
    "W_{K} \\approx  \\left( \\tilde{W}^{avg}_{K N_{mc}} \\pm \\delta \\tilde{W}^{avg}_{K N_{mc}} \\right) \\ .\n",
    "$$\n",
    "\n",
    "$\\textbf{This quantity is plotted in the companion notebook}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
